{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eck\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.0-rc1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "from model_tf2 import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 16, 16, 16)\n",
    "output_channels = 3\n",
    "dummy_x = np.random.randn(10, *input_shape)\n",
    "dummy_y = np.random.randn(10, output_channels, *input_shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv3d_autoenc_reg(keras.Model):\n",
    "    def __init__(self, input_shape=(4, 160, 192, 128), output_channels=3, l2_reg_weight = 1e-5, weight_L2=0.1, weight_KL=0.1, \n",
    "                 dice_e=1e-8, test_mode = True, n_gpu = 1, GL_weight = 1, VL_weight = 0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.c, self.H, self.W, self.D = input_shape\n",
    "        self.n = self.c * self.H * self.W * self.D\n",
    "        assert len(input_shape) == 4, \"Input shape must be a 4-tuple\"\n",
    "        if test_mode is not True: assert (self.c % 4) == 0, \"The no. of channels must be divisible by 4\"\n",
    "        assert (self.H % 16) == 0 and (self.W % 16) == 0 and (self.D % 16) == 0, \"All the input dimensions must be divisible by 16\"\n",
    "        self.l2_regularizer = l2(l2_reg_weight) if l2_reg_weight is not None else None\n",
    "        \n",
    "        self.input_shape_p = input_shape\n",
    "        self.output_channels = output_channels\n",
    "        self.l2_reg_weight = l2_reg_weight\n",
    "        self.weight_L2 = weight_L2\n",
    "        self.weight_KL = weight_KL\n",
    "        self.dice_e = dice_e\n",
    "        self.GL_weight = GL_weight\n",
    "        self.VL_weight = VL_weight\n",
    "        \n",
    "        self.LossVAE = LossVAE(weight_L2, weight_KL, self.n)\n",
    "        \n",
    "        ## The Initial Block\n",
    "        self.Input_x1 = Conv3D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3, 3),\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_regularizer = self.l2_regularizer,\n",
    "        data_format='channels_first',\n",
    "        name='Input_x1')\n",
    "        \n",
    "        ## Dropout (0.2)\n",
    "        self.spatial_dropout = SpatialDropout3D(0.2, data_format='channels_first')\n",
    "        \n",
    "        ## Green Block x1 (output filters = 32)\n",
    "        self.x1 = green_block(32, regularizer = self.l2_regularizer, name='x1')\n",
    "        self.Enc_DownSample_32 = Conv3D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3, 3),\n",
    "            strides=2,\n",
    "            padding='same',\n",
    "            kernel_regularizer = self.l2_regularizer,\n",
    "            data_format='channels_first',\n",
    "            name='Enc_DownSample_32')\n",
    "        \n",
    "        ## Green Block x2 (output filters = 64)\n",
    "        self.Enc_64_1 = green_block(64, regularizer = self.l2_regularizer, name='Enc_64_1')\n",
    "        self.x2 = green_block(64, regularizer = self.l2_regularizer, name='x2')\n",
    "        self.Enc_DownSample_64 = Conv3D(\n",
    "                            filters=64,\n",
    "                            kernel_size=(3, 3, 3),\n",
    "                            strides=2,\n",
    "                            padding='same',\n",
    "                            kernel_regularizer = self.l2_regularizer,\n",
    "                            data_format='channels_first',\n",
    "                            name='Enc_DownSample_64')\n",
    "        \n",
    "        ## Green Blocks x2 (output filters = 128)\n",
    "        self.Enc_128_1 = green_block(128, regularizer = self.l2_regularizer, name='Enc_128_1')\n",
    "        self.x3 = green_block(128, regularizer = self.l2_regularizer, name='x3')\n",
    "        self.Enc_DownSample_128 = Conv3D(filters=128, kernel_size=(3, 3, 3), strides=2, padding='same', kernel_regularizer = self.l2_regularizer, \n",
    "                                         data_format='channels_first', name='Enc_DownSample_128')\n",
    "        \n",
    "        ## Green Blocks x4 (output filters = 256)\n",
    "        self.Enc_256_1 = green_block(256, regularizer = self.l2_regularizer, name='Enc_256_1')\n",
    "        self.Enc_256_2 = green_block(256, regularizer = self.l2_regularizer, name='Enc_256_2')\n",
    "        self.Enc_256_3 = green_block(256, regularizer = self.l2_regularizer, name='Enc_256_3')\n",
    "        self.x4 = green_block(256, regularizer = self.l2_regularizer, name='x4')\n",
    "        \n",
    "        # -------------------------------------------------------------------------\n",
    "        # Decoder\n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "        ## GT (Groud Truth) Part\n",
    "        # -------------------------------------------------------------------------\n",
    "        \n",
    "        ### Green Block x1 (output filters=128)\n",
    "        self.Dec_GT_ReduceDepth_128 = Conv3D(filters=128, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first', name='Dec_GT_ReduceDepth_128')\n",
    "        self.Dec_GT_UpSample_128 = UpSampling3D(size=2, data_format='channels_first', name='Dec_GT_UpSample_128') \n",
    "        self.Input_Dec_GT_128 = Add(name='Input_Dec_GT_128')\n",
    "        self.Dec_GT_128 = green_block(128, regularizer = self.l2_regularizer, name='Dec_GT_128')\n",
    "        \n",
    "        ### Green Block x1 (output filters=64)\n",
    "        self.Dec_GT_ReduceDepth_64 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first', name='Dec_GT_ReduceDepth_64')\n",
    "        self.Dec_GT_UpSample_64 = UpSampling3D(size=2, data_format='channels_first', name='Dec_GT_UpSample_64')\n",
    "        self.Input_Dec_GT_64 = Add(name='Input_Dec_GT_64')\n",
    "        self.Dec_GT_64 = green_block(64, regularizer = self.l2_regularizer, name='Dec_GT_64')\n",
    "        \n",
    "        ### Green Block x1 (output filters=32)\n",
    "        self.Dec_GT_ReduceDepth_32 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first', \n",
    "                                       name='Dec_GT_ReduceDepth_32')\n",
    "        self.Dec_GT_UpSample_32 = UpSampling3D(size=2, data_format='channels_first', name='Dec_GT_UpSample_32')\n",
    "        self.Input_Dec_GT_32 = Add(name='Input_Dec_GT_32')\n",
    "        self.Dec_GT_32 = green_block(32, regularizer = self.l2_regularizer, name='Dec_GT_32')\n",
    "        \n",
    "        ### Blue Block x1 (output filters=32)\n",
    "        self.Input_Dec_GT_Output = Conv3D(filters=32, kernel_size=(3, 3, 3), strides=1, padding='same', kernel_regularizer = self.l2_regularizer, \n",
    "                                     data_format='channels_first', name='Input_Dec_GT_Output')\n",
    "        \n",
    "        ### Output Block\n",
    "        self.Dec_GT_Output = Conv3D(filters=self.output_channels, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, \n",
    "                                data_format='channels_first', activation='sigmoid', name='Dec_GT_Output')\n",
    "        \n",
    "        ## VAE (Variational Auto Encoder) Part\n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "        ### VD Block (Reducing dimensionality of the data)\n",
    "        self.Dec_VAE_VD_GN = GroupNormalization(groups=8, axis=1, name='Dec_VAE_VD_GN')\n",
    "        self.Dec_VAE_VD_relu = Activation('relu', name='Dec_VAE_VD_relu')\n",
    "        self.Dec_VAE_VD_Conv3D = Conv3D(filters=16, kernel_size=(3, 3, 3), strides=2, padding='same', kernel_regularizer = self.l2_regularizer, \n",
    "                                   data_format='channels_first', name='Dec_VAE_VD_Conv3D')\n",
    "        \n",
    "        # Not mentioned in the paper, but the author used a Flattening layer here.\n",
    "        self.Dec_VAE_VD_Flatten = Flatten(name='Dec_VAE_VD_Flatten')\n",
    "        self.Dec_VAE_VD_Dense = Dense(256, name='Dec_VAE_VD_Dense')\n",
    "\n",
    "        ### VDraw Block (Sampling)\n",
    "        self.Dec_VAE_VDraw_Mean = Dense(128, name='Dec_VAE_VDraw_Mean')\n",
    "        self.Dec_VAE_VDraw_Var = Dense(128, name='Dec_VAE_VDraw_Var')\n",
    "#         self.Dec_VAE_VDraw_Sampling = Lambda(sampling, name='Dec_VAE_VDraw_Sampling')\n",
    "        self.Dec_VAE_VDraw_Sampling = sampling()\n",
    "\n",
    "        ### VU Block (Upsizing back to a depth of 256)\n",
    "        c1 = 1\n",
    "        self.VU_Dense1 = Dense((c1) * (self.H//16) * (self.W//16) * (self.D//16))\n",
    "        self.VU_relu = Activation('relu')\n",
    "        self.VU_reshape = Reshape(((c1), (self.H//16), (self.W//16), (self.D//16)))\n",
    "        self.Dec_VAE_ReduceDepth_256 = Conv3D(filters=256, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first',\n",
    "                                            name='Dec_VAE_ReduceDepth_256')\n",
    "        self.Dec_VAE_UpSample_256 = UpSampling3D(size=2, data_format='channels_first', name='Dec_VAE_UpSample_256')\n",
    "\n",
    "        ### Green Block x1 (output filters=128)\n",
    "        self.Dec_VAE_ReduceDepth_128 = Conv3D(filters=128, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first', \n",
    "                                         name='Dec_VAE_ReduceDepth_128')\n",
    "        self.Dec_VAE_UpSample_128 = UpSampling3D(size=2, data_format='channels_first', name='Dec_VAE_UpSample_128')\n",
    "        self.Dec_VAE_128 = green_block(128, regularizer = self.l2_regularizer, name='Dec_VAE_128')\n",
    "\n",
    "        ### Green Block x1 (output filters=64)\n",
    "        self.Dec_VAE_ReduceDepth_64 = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first',\n",
    "                                        name='Dec_VAE_ReduceDepth_64')\n",
    "        self.Dec_VAE_UpSample_64 = UpSampling3D(size=2, data_format='channels_first', name='Dec_VAE_UpSample_64')\n",
    "        self.Dec_VAE_64 = green_block(64, regularizer = self.l2_regularizer, name='Dec_VAE_64')\n",
    "\n",
    "        ### Green Block x1 (output filters=32)\n",
    "        self.Dec_VAE_ReduceDepth_32 = Conv3D(filters=32, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first',\n",
    "                                        name='Dec_VAE_ReduceDepth_32')\n",
    "        self.Dec_VAE_UpSample_32 = UpSampling3D(size=2, data_format='channels_first', name='Dec_VAE_UpSample_32')\n",
    "        self.Dec_VAE_32 = green_block(32, regularizer = self.l2_regularizer, name='Dec_VAE_32')\n",
    "\n",
    "        ### Blue Block x1 (output filters=32)\n",
    "        self.Input_Dec_VAE_Output = Conv3D(filters=32, kernel_size=(3, 3, 3), strides=1, padding='same', kernel_regularizer = self.l2_regularizer, \n",
    "                                      data_format='channels_first', name='Input_Dec_VAE_Output')\n",
    "\n",
    "        ### Output Block\n",
    "        self.Dec_VAE_Output = Conv3D(filters=self.c, kernel_size=(1, 1, 1), strides=1, kernel_regularizer = self.l2_regularizer, data_format='channels_first', \n",
    "                                     name='Dec_VAE_Output')\n",
    "        \n",
    "#     def build(self, batch_input_shape):\n",
    "#         n_inputs = batch_input_shape[-1]\n",
    "        \n",
    "#         ### super build\n",
    "#         super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        x = self.Input_x1(Z)\n",
    "        \n",
    "        ## Dropout (0.2)\n",
    "        x = self.spatial_dropout(x)\n",
    "\n",
    "        ## Green Block x1 (output filters = 32)\n",
    "        x1 = self.x1(x)\n",
    "        x = self.Enc_DownSample_32(x1)\n",
    "\n",
    "        ## Green Block x2 (output filters = 64)\n",
    "        x = self.Enc_64_1(x)\n",
    "        x2 = self.x2(x)\n",
    "        x = self.Enc_DownSample_64(x2)\n",
    "\n",
    "        ## Green Blocks x2 (output filters = 128)\n",
    "        x = self.Enc_128_1(x)\n",
    "        x3 = self.x3(x)\n",
    "        x = self.Enc_DownSample_128(x3)\n",
    "\n",
    "        ## Green Blocks x4 (output filters = 256)\n",
    "        x = self.Enc_256_1(x)\n",
    "        x = self.Enc_256_2(x)\n",
    "        x = self.Enc_256_3(x)\n",
    "        x4 = self.x4(x)\n",
    "\n",
    "        # -------------------------------------------------------------------------\n",
    "        # Decoder\n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "        ## GT (Groud Truth) Part\n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "        ### Green Block x1 (output filters=128)\n",
    "        x = self.Dec_GT_ReduceDepth_128(x4)\n",
    "        x = self.Dec_GT_UpSample_128(x)\n",
    "        x = self.Input_Dec_GT_128([x, x3])\n",
    "        x = self.Dec_GT_128(x)\n",
    "\n",
    "        ### Green Block x1 (output filters=64)\n",
    "        x = self.Dec_GT_ReduceDepth_64(x)\n",
    "        x = self.Dec_GT_UpSample_64(x)\n",
    "        x = self.Input_Dec_GT_64([x, x2])\n",
    "        x = self.Dec_GT_64(x)\n",
    "\n",
    "        ### Green Block x1 (output filters=32)\n",
    "        x = self.Dec_GT_ReduceDepth_32(x)\n",
    "        x = self.Dec_GT_UpSample_32(x)\n",
    "        x = self.Input_Dec_GT_32([x, x1])\n",
    "        x = self.Dec_GT_32(x)\n",
    "\n",
    "        ### Blue Block x1 (output filters=32)\n",
    "        x = self.Input_Dec_GT_Output(x)\n",
    "\n",
    "        ### Output Block\n",
    "        out_GT = self.Dec_GT_Output(x)\n",
    "\n",
    "        ## VAE (Variational Auto Encoder) Part\n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "        ### VD Block (Reducing dimensionality of the data)\n",
    "        x = self.Dec_VAE_VD_GN(x4)\n",
    "        x = self.Dec_VAE_VD_relu(x)\n",
    "        x = self.Dec_VAE_VD_Conv3D(x)\n",
    "\n",
    "        # Not mentioned in the paper, but the author used a Flattening layer here.\n",
    "        x = self.Dec_VAE_VD_Flatten(x)\n",
    "        x = self.Dec_VAE_VD_Dense(x)\n",
    "\n",
    "        ### VDraw Block (Sampling)\n",
    "        z_mean = self.Dec_VAE_VDraw_Mean(x)\n",
    "        z_var = self.Dec_VAE_VDraw_Var(x)\n",
    "        x = self.Dec_VAE_VDraw_Sampling([z_mean, z_var])\n",
    "\n",
    "        ### VU Block (Upsizing back to a depth of 256)\n",
    "        x = self.VU_Dense1(x)\n",
    "        x = self.VU_relu(x)\n",
    "        x = self.VU_reshape(x)\n",
    "        x = self.Dec_VAE_ReduceDepth_256(x)\n",
    "        x = self.Dec_VAE_UpSample_256(x)\n",
    "\n",
    "        ### Green Block x1 (output filters=128)\n",
    "        x = self.Dec_VAE_ReduceDepth_128(x)\n",
    "        x = self.Dec_VAE_UpSample_128(x)\n",
    "        x = self.Dec_VAE_128(x)\n",
    "\n",
    "        ### Green Block x1 (output filters=64)\n",
    "        x = self.Dec_VAE_ReduceDepth_64(x)\n",
    "        x = self.Dec_VAE_UpSample_64(x)\n",
    "        x = self.Dec_VAE_64(x)\n",
    "\n",
    "        ### Green Block x1 (output filters=32)\n",
    "        x = self.Dec_VAE_ReduceDepth_32(x)\n",
    "        x = self.Dec_VAE_UpSample_32(x)\n",
    "        x = self.Dec_VAE_32(x)\n",
    "\n",
    "        ### Blue Block x1 (output filters=32)\n",
    "        x = self.Input_Dec_VAE_Output(x)\n",
    "\n",
    "        ### Output Block\n",
    "        out_VAE = self.Dec_VAE_Output(x) \n",
    "        \n",
    "#         self.LossVAE([Z, out_VAE, z_mean, z_var])\n",
    "        \n",
    "        return out_GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv3d_autoenc_reg(input_shape, output_channels, l2_reg_weight = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-4, clipvalue=0.5)\n",
    "lg = DiceLoss()\n",
    "dc = dice_coefficient\n",
    "\n",
    "model.compile(\n",
    "    opt,\n",
    "    [lg],\n",
    "    metrics=[dc],\n",
    "    loss_weights = [1.]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['conv3d_autoenc_reg/Dec_VAE_VD_GN/gamma:0', 'conv3d_autoenc_reg/Dec_VAE_VD_GN/beta:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Conv3D/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Conv3D/bias:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Dense/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Dense/bias:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Mean/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Mean/bias:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Var/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Var/bias:0', 'conv3d_autoenc_reg/dense/kernel:0', 'conv3d_autoenc_reg/dense/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_256/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_256/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_128/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_128/bias:0', 'conv3d_autoenc_reg/green_block_12/Res_Dec_VAE_128/kernel:0', 'conv3d_autoenc_reg/green_block_12/Res_Dec_VAE_128/bias:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_1_Dec_VAE_128/gamma:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_1_Dec_VAE_128/beta:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_1_Dec_VAE_128/kernel:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_1_Dec_VAE_128/bias:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_2_Dec_VAE_128/gamma:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_2_Dec_VAE_128/beta:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_2_Dec_VAE_128/kernel:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_2_Dec_VAE_128/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_64/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_64/bias:0', 'conv3d_autoenc_reg/green_block_13/Res_Dec_VAE_64/kernel:0', 'conv3d_autoenc_reg/green_block_13/Res_Dec_VAE_64/bias:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_1_Dec_VAE_64/gamma:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_1_Dec_VAE_64/beta:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_1_Dec_VAE_64/kernel:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_1_Dec_VAE_64/bias:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_2_Dec_VAE_64/gamma:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_2_Dec_VAE_64/beta:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_2_Dec_VAE_64/kernel:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_2_Dec_VAE_64/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_32/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_32/bias:0', 'conv3d_autoenc_reg/green_block_14/Res_Dec_VAE_32/kernel:0', 'conv3d_autoenc_reg/green_block_14/Res_Dec_VAE_32/bias:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_1_Dec_VAE_32/gamma:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_1_Dec_VAE_32/beta:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_1_Dec_VAE_32/kernel:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_1_Dec_VAE_32/bias:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_2_Dec_VAE_32/gamma:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_2_Dec_VAE_32/beta:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_2_Dec_VAE_32/kernel:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_2_Dec_VAE_32/bias:0', 'conv3d_autoenc_reg/Input_Dec_VAE_Output/kernel:0', 'conv3d_autoenc_reg/Input_Dec_VAE_Output/bias:0', 'conv3d_autoenc_reg/Dec_VAE_Output/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_Output/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['conv3d_autoenc_reg/Dec_VAE_VD_GN/gamma:0', 'conv3d_autoenc_reg/Dec_VAE_VD_GN/beta:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Conv3D/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Conv3D/bias:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Dense/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VD_Dense/bias:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Mean/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Mean/bias:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Var/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_VDraw_Var/bias:0', 'conv3d_autoenc_reg/dense/kernel:0', 'conv3d_autoenc_reg/dense/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_256/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_256/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_128/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_128/bias:0', 'conv3d_autoenc_reg/green_block_12/Res_Dec_VAE_128/kernel:0', 'conv3d_autoenc_reg/green_block_12/Res_Dec_VAE_128/bias:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_1_Dec_VAE_128/gamma:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_1_Dec_VAE_128/beta:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_1_Dec_VAE_128/kernel:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_1_Dec_VAE_128/bias:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_2_Dec_VAE_128/gamma:0', 'conv3d_autoenc_reg/green_block_12/GroupNorm_2_Dec_VAE_128/beta:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_2_Dec_VAE_128/kernel:0', 'conv3d_autoenc_reg/green_block_12/Conv3D_2_Dec_VAE_128/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_64/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_64/bias:0', 'conv3d_autoenc_reg/green_block_13/Res_Dec_VAE_64/kernel:0', 'conv3d_autoenc_reg/green_block_13/Res_Dec_VAE_64/bias:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_1_Dec_VAE_64/gamma:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_1_Dec_VAE_64/beta:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_1_Dec_VAE_64/kernel:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_1_Dec_VAE_64/bias:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_2_Dec_VAE_64/gamma:0', 'conv3d_autoenc_reg/green_block_13/GroupNorm_2_Dec_VAE_64/beta:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_2_Dec_VAE_64/kernel:0', 'conv3d_autoenc_reg/green_block_13/Conv3D_2_Dec_VAE_64/bias:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_32/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_ReduceDepth_32/bias:0', 'conv3d_autoenc_reg/green_block_14/Res_Dec_VAE_32/kernel:0', 'conv3d_autoenc_reg/green_block_14/Res_Dec_VAE_32/bias:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_1_Dec_VAE_32/gamma:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_1_Dec_VAE_32/beta:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_1_Dec_VAE_32/kernel:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_1_Dec_VAE_32/bias:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_2_Dec_VAE_32/gamma:0', 'conv3d_autoenc_reg/green_block_14/GroupNorm_2_Dec_VAE_32/beta:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_2_Dec_VAE_32/kernel:0', 'conv3d_autoenc_reg/green_block_14/Conv3D_2_Dec_VAE_32/bias:0', 'conv3d_autoenc_reg/Input_Dec_VAE_Output/kernel:0', 'conv3d_autoenc_reg/Input_Dec_VAE_Output/bias:0', 'conv3d_autoenc_reg/Dec_VAE_Output/kernel:0', 'conv3d_autoenc_reg/Dec_VAE_Output/bias:0'] when minimizing the loss.\n",
      "1/5 [=====>........................] - ETA: 2:06 - loss: -0.6211 - dice_coefficient: 0.6211"
     ]
    }
   ],
   "source": [
    "model.fit(dummy_x, dummy_y, batch_size = 2, epochs = 1, callbacks = [], validation_data = (dummy_x, dummy_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp.sound_alert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
